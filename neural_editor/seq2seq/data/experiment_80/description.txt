Same as 79, but no neural editor is used. Also in this version bug with BLEU calculation was fixed.

Observations:
BLEU and acc on all epochs is zero.
Duration: only 50 epochs
Model cannot generalize, val ppl doesn't go down.
This model always predicts "fix npe ..."
80 vs 79(not finished yet)
neural editor

commit message generator
best_val_perplexity: 511.47 (on epoch 18)
last_train_perplexity: 87.99
test_acc: 0.0015
train_acc_test_size: 0.0015
train_acc_test_size top-5: 0.006
BLEU test: 0
BLEU train: 0
hyp_len / ref_len (on test): 0.313

Conclusions: looks like data is very hard for model to predict, also train ppl is high. This can be because amount of data is very small.
