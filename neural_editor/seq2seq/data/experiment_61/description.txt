Same as 59, but dataset is filtered.

Observations:
61 vs 59
Loss plots look pretty the same
commit message generator
best_val_perplexity: 49.76 vs 60.79 (better)
last_train_perplexity: 7.89 vs 11.22 (better)
test_acc: 0.158 vs 0.073 (much better)
train_acc_test_size: 0.168 vs 0.078 (much better)
train_acc_test_size top-50: 0.278 vs 0.217 (much better)
BLEU test: 31.33 vs 23.36 (much better)
BLEU train: 32.18 vs 24.03 (much better)
hyp_len / ref_len (on test): 0.545 vs 0.501 (better)

Conclusions: Dataset reduced from 26K to 20K samples. Looks like filtering removes a lot of noise from the dataset and makes results better. It becomes much comparable with (True, filtered_part + filtered_cmg_part, 16, True) solution, even without copying mechanism. But true comparison should be conducted on the same datasets.
