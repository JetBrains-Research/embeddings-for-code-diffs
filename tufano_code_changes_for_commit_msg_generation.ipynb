{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we use Tufano Code Changes Dataset for commit message generation task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At least we must have commit messages. We have them in cvs file describing PRs. Some PRs are large, but some of them are small (we need small). Also Tufano had extracted method pairs. Here we can go several ways: attach commit messages to existing datapoints or collect those changes that have single method pair changed. First method is worse because some changes have mutliple method pairs. Therefore one method pair can be not enough to generate commit message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we go with first method we have same dataset size: 21774"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how many datapoints we could have if we go with second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_ALL_IDS = {}\n",
    "LIST_OF_SINGLE_CHANGED_FILES = {}\n",
    "METHOD_LENGTHS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caclulate_for_project(project):\n",
    "    import os\n",
    "    def is_single_changed(i):\n",
    "        return len(os.listdir(f'../Tufano_data/{project}/{i}')) == 1 and len(os.listdir(f'../Tufano_data/{project}/{i}/0/')) == 1 and len(os.listdir(f'../Tufano_data/{project}/{i}/0/0')) == 4\n",
    "    \n",
    "    def calculate_method_length(i):\n",
    "        METHOD_LENGTHS[project][i] = 0\n",
    "        length = 0\n",
    "        filenames = ['before.java', 'after.java']\n",
    "        for filename in filenames:\n",
    "            with open(f'../Tufano_data/{project}/{i}/0/0/{filename}', 'r') as f:\n",
    "                for line in f:\n",
    "                    METHOD_LENGTHS[project][i] += len(line.split())\n",
    "        METHOD_LENGTHS[project][i] /= len(filenames)\n",
    "    LIST_OF_ALL_IDS[project] = [i for i in os.listdir(f'../Tufano_data/{project}')]\n",
    "    LIST_OF_SINGLE_CHANGED_FILES[project] = [i for i in LIST_OF_ALL_IDS[project] if is_single_changed(i)]\n",
    "    METHOD_LENGTHS[project] = {}\n",
    "    for i in LIST_OF_SINGLE_CHANGED_FILES[project]:\n",
    "        calculate_method_length(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "caclulate_for_project('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "caclulate_for_project('google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "caclulate_for_project('ovirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_on_single_datapoints():\n",
    "    total_single = 0\n",
    "    total = 0\n",
    "    for project in LIST_OF_ALL_IDS.keys():\n",
    "        total_single += len(LIST_OF_SINGLE_CHANGED_FILES[project])\n",
    "        total += len(LIST_OF_ALL_IDS[project])\n",
    "        print(f'{project}: {len(LIST_OF_SINGLE_CHANGED_FILES[project])} / {len(LIST_OF_ALL_IDS[project])} = {round(len(LIST_OF_SINGLE_CHANGED_FILES[project]) / len(LIST_OF_ALL_IDS[project]), 2)}')\n",
    "    print(f'total: {total_single} / {total} = {round(total_single / total, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android: 8515 / 22746 = 0.37\n",
      "google: 5087 / 14099 = 0.36\n",
      "ovirt: 7591 / 22800 = 0.33\n",
      "total: 21193 / 59645 = 0.36\n"
     ]
    }
   ],
   "source": [
    "print_statistics_on_single_datapoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_methods_lengths_statistics(upper_bound=100):\n",
    "    import numpy as np\n",
    "    total_single = []\n",
    "    for project in LIST_OF_ALL_IDS.keys():\n",
    "        lengths = list(METHOD_LENGTHS[project].values())\n",
    "        total_single += lengths\n",
    "        np_lengths = np.array(lengths)\n",
    "        print(f'{project}: mean = {round(np.mean(lengths))} std = {round(np.std(lengths))} len(<={upper_bound}) = {len(np_lengths[np_lengths <= upper_bound])}')\n",
    "    np_total_single = np.array(total_single)\n",
    "    print(f'total: mean = {round(np.mean(total_single))} std = {round(np.std(total_single))} {len(np_total_single[np_total_single <= upper_bound])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android: mean = 146.0 std = 278.0 len(<=100) = 5140\n",
      "google: mean = 94.0 std = 91.0 len(<=100) = 3403\n",
      "ovirt: mean = 75.0 std = 109.0 len(<=100) = 5951\n",
      "total: mean = 108.0 std = 196.0 14494\n"
     ]
    }
   ],
   "source": [
    "print_methods_lengths_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CSV_DATA = pd.read_csv('../Tufano_data/PullRequests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pull Request ID', 'URL', 'Project Name', 'Title',\n",
       "       'Creation Timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_DATA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_MESSAGES = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ind_to_row():\n",
    "    ind_to_row = {'android': {}, 'google': {}, 'ovirt': {}}\n",
    "    project_prefixes = {'android': 'android', 'google': 'gerrit-review', 'ovirt': 'gerrit.ovirt'}\n",
    "    for j, url in enumerate(CSV_DATA['URL']):\n",
    "        for project, project_prefix in project_prefixes.items():\n",
    "            if url.startswith(project_prefix):\n",
    "                ind_to_row[project][str(CSV_DATA['Pull Request ID'][j])] = j\n",
    "    return ind_to_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_TO_ROW = generate_ind_to_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_commit_messages(project):\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    def get_row_in_csv(i):\n",
    "        if i not in IND_TO_ROW[project].keys():\n",
    "            return None\n",
    "        return IND_TO_ROW[project][i]\n",
    "    def get_commit_msg(i):\n",
    "        row = get_row_in_csv(i)\n",
    "        if row is None:\n",
    "            print(f'For PR with ID = {i} in project {project} record not found in csv file.')\n",
    "            return None\n",
    "        return CSV_DATA['Title'][row]\n",
    "    \n",
    "    COMMIT_MESSAGES[project] = {}\n",
    "    for i in tqdm(LIST_OF_SINGLE_CHANGED_FILES[project]):\n",
    "        msg =  get_commit_msg(i)\n",
    "        if msg is not None:\n",
    "            COMMIT_MESSAGES[project][i] = get_commit_msg(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ee12915935485399dfbbadc9696489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5087), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_commit_messages('google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do cheaper checks first in GroupCountrol.isVisible'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMIT_MESSAGES['google']['64710'] # should be 'Do cheaper checks first in GroupCountrol.isVisible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ignore errors when current row no longer exists in a table',\n",
       " 'Fixing jdbc code: correct PreparedStatement closing',\n",
       " 'Allow publishing old non-current patch sets',\n",
       " 'Fix possible NPE in LsUserRefs',\n",
       " 'Use context user for change message on submit',\n",
       " 'Fixed regression caused by the defaultValue feature',\n",
       " 'ChangeScreen2: Add title tooltip to reviewed checkbox',\n",
       " 'SetReadyForReview: Change action label to \"Start Review\"',\n",
       " 'Remove unused members',\n",
       " 'Move a lot of the state for unifiedPatchDetailAction into the base',\n",
       " 'BugFix on latest GitHub API: list repos from private repos',\n",
       " 'ReceiveCommits.ReplaceRequest: Parse prior commit body earlier',\n",
       " 'Mergeable: Reindex change asynchronously',\n",
       " 'CloneWithCommitMsgHook: Fix HTTP clone command inconsistency',\n",
       " 'Open RevWalk in try-with-resource',\n",
       " 'Fix wrong date/time for commits in refs/users/default branch',\n",
       " 'init: ensure that tmp dir exists before extracting plugins',\n",
       " 'RelativeDateFormatter: Simplify rounding of years and months',\n",
       " \"Don't allow the project name in change tables to wrap\",\n",
       " \"HostIndexServlet: Don't use deprecated SoyData.createFromExistingData\"]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(COMMIT_MESSAGES['google'].values()), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4428170b09e84fee876c247e29f6682b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7591), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_commit_messages('ovirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"webadmin: Sync file size and uploaded image's actual size.\",\n",
       " 'engine : Async tasks should handle exception in creating task',\n",
       " 'core: Replacing StringUtils for StringHelper in LdapBrokerCommandBase.',\n",
       " 'tools: Fixes password prompt for admin user',\n",
       " 'gluster: fix releasing lock in task sync-job',\n",
       " 'webadmin: display SD status in Storage sub-tab',\n",
       " 'core: DirectorySearcherTest: reduce timeouts',\n",
       " 'restapi: Fix backend vm resource test failure',\n",
       " 'core: @Inject GetVnicProfilesByDataCenterIdQuery Daos',\n",
       " 'restapi: Remove \"DnsServers\" and \"DnsServer\" complex types',\n",
       " 'core: Use container id for memory lock in import process.',\n",
       " 'core: [ExternalTasks] Cannot end existing job',\n",
       " 'restapi: Do not cast memory.used to int',\n",
       " 'core: AuditLogableBase: @Inject VdsKdumpStatusDao',\n",
       " 'core: do not set run-on-vds name in monitoring',\n",
       " 'tools: fix error logging',\n",
       " 'core: ProcessOvfUpdate - skip vms/templates without ovf',\n",
       " 'core: Fix MathUtils.greatestCommonDivisor()',\n",
       " 'core: fix reattempt to go to maintenance mechanism',\n",
       " 'frontend: Fix issues with VmRngDevice.Source enum']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(COMMIT_MESSAGES['ovirt'].values()), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13203227c4384497a8e97efd33aef132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8515), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For PR with ID = 664242 in project android record not found in csv file.\n",
      "For PR with ID = 688460 in project android record not found in csv file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_commit_messages('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fix suspend crash issue on no GPU platform.',\n",
       " 'Fix renderscript compilation from Ant.',\n",
       " 'Remove an incorrect assert',\n",
       " 'DO NOT MERGE fix failing test testWifiInfoProperties for non-telephony devices',\n",
       " 'NullPointerException invoking Field.getModifiers',\n",
       " 'Renamed getNetworkId and getSystemId',\n",
       " 'Adds CTS test for Script.Closure.getGlobal()',\n",
       " 'Move the \"huge method\" test into its own test case.',\n",
       " 'Scan for methods in extra interface hierarchy',\n",
       " 'Match language-specific flags before default locale country matches',\n",
       " 'Fix crash on ending call.',\n",
       " 'Allow to share classloader for non-inline dexmaker',\n",
       " 'payment: Do not reset the default payment is non-null.',\n",
       " 'Fix merging HLoadClass with HNewInstance.',\n",
       " 'Remove obsolete getIsimChallengeResponse',\n",
       " 'HFP-Client: Set current device to null after firing broadcast',\n",
       " '75700: Do not flag appcompat method suggestions in non-appcompat activities',\n",
       " 'Fix NotificationManagerTest.checkNotificationExistence',\n",
       " 'DO NOT MERGE - [ActivityManager] Ensure consistency behavior when a background activity brings another existed activity to front.',\n",
       " 'A2dpSink stopFluorideStreaming']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(COMMIT_MESSAGES['android'].values()), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see some patterns: \"Seq1: Seq2\". Maybe it is good idea to leave only \"Seq2\". Also, we should probably delete punctuations ('.' in the end of messages). Also, we should remove those which contain MERGE if there are a lot of such samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_prefixes(prefix_bounds):\n",
    "    print(f'Prefix \":\" statistics with bounds: {prefix_bounds}')\n",
    "    def get_prefix_num(commit_msgs_dict, bounds):\n",
    "        if bounds is None:\n",
    "            with_prefix = [msg for msg in commit_msgs_dict.values() if ':' in msg]\n",
    "        else:\n",
    "            with_prefix = [msg for msg in commit_msgs_dict.values() if bounds[0] <= msg.count(':') < bounds[1]]\n",
    "        return len(with_prefix)\n",
    "    \n",
    "    total_prefix_num = 0\n",
    "    total = 0\n",
    "    for project, commit_mgs in COMMIT_MESSAGES.items():\n",
    "        prefix_num = get_prefix_num(commit_mgs, prefix_bounds)\n",
    "        total_prefix_num += prefix_num\n",
    "        total += len(commit_mgs)\n",
    "        print(f'{project}: {prefix_num} / {len(commit_mgs)} = {prefix_num / len(commit_mgs)}')\n",
    "    print(f'total: {total_prefix_num} / {total} = {total_prefix_num / total}')\n",
    "\n",
    "def print_commit_msg_statistics(prefix_bounds):\n",
    "    print_number_of_prefixes(prefix_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix \":\" statistics with bounds: None\n",
      "google: 1387 / 5087 = 0.27265578926675843\n",
      "android: 1797 / 8513 = 0.21108892282391636\n",
      "ovirt: 7305 / 7591 = 0.9623238045053353\n",
      "total: 10489 / 21191 = 0.49497428153461376\n"
     ]
    }
   ],
   "source": [
    "print_commit_msg_statistics(prefix_bounds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix \":\" statistics with bounds: (1, 2)\n",
      "google: 1381 / 5087 = 0.27147631216827206\n",
      "android: 1633 / 8513 = 0.1918242687654176\n",
      "ovirt: 7050 / 7591 = 0.928731392438414\n",
      "total: 10064 / 21191 = 0.4749185975178142\n"
     ]
    }
   ],
   "source": [
    "print_commit_msg_statistics(prefix_bounds=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see half of samples are \"seq1: seq2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_after_filtering(predicate, label, n_sample):\n",
    "    print(f'Filtering: {label}')\n",
    "    total_filtered = 0\n",
    "    total = 0\n",
    "    for project, commit_mgs in COMMIT_MESSAGES.items():\n",
    "        filtered = list(filter(predicate, commit_mgs.values()))\n",
    "        total_filtered += len(filtered)\n",
    "        total += len(commit_mgs)\n",
    "        print(random.sample(filtered, min(n_sample, len(filtered))))\n",
    "        print(f'{project}: {len(filtered)} / {len(commit_mgs)} = {len(filtered) / len(commit_mgs)}')\n",
    "    print(f'total: {total_filtered} / {total} = {total_filtered / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \": \" in msg once\n",
      "['SiteLibraryLoaderUtil: catch NoSuchFileException when scanning for JARs', 'OAuth extension point: Allow to authenticate without email', 'ChangeInserter: fix comparison of Change.Id to Change.Key']\n",
      "google: 1358 / 5087 = 0.26695498329074113\n",
      "['PBAP: remove dead code', 'Telephony: Fix call forward info logging.', 'Test: skip video test for watch']\n",
      "android: 1594 / 8513 = 0.18724304005638434\n",
      "['frontend: Fix NPE in ImportVmFromExternalSourceModel', 'core: Fix RandomUtils#nextPropertyString', \"webadmin: Don't trigger event when assigning label\"]\n",
      "ovirt: 6998 / 7591 = 0.9218811750757476\n",
      "total: 9950 / 21191 = 0.46953895521683736\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 1 <= msg.count(':') < 2 and ': ' in msg, '\": \" in msg once', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: only one word before \":\"\n",
      "['HostPageServlet: Avoid no-op Cookie#setHttpOnly call', 'MergeSuperSet: Inline empty set', 'ReviewerRecommender: Make array of weights a constant']\n",
      "google: 1251 / 5087 = 0.2459209750344014\n",
      "['LocationManagerService: Fix bug removing proximity alerts.', 'CTS: clear notification when testPerformGlobalActionQuickSettings is done', 'sun.security.pkcs: type tyding. Port from jdk8u60']\n",
      "android: 1243 / 8513 = 0.14601198167508517\n",
      "[\"webadmin: v2v-tooltip for XEN's URI field is not truncated\", 'engine: fix repeatedly duplicated events in subtabs', 'restapi: Add API to support warning for attached Storage Domains']\n",
      "ovirt: 6940 / 7591 = 0.914240548017389\n",
      "total: 9434 / 21191 = 0.4451889953282054\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 1 <= msg.count(':') < 2 and len(msg.split(':')[0].split()) == 1, 'only one word before \":\"', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: more than two \":\"\n",
      "['Close DirContext context in LdapRealm::isActive', 'Make bug: an alias for tr: in search', 'ChangeNoteUtil: Fix parsing of \"0:0-0:0\" range']\n",
      "google: 6 / 5087 = 0.0011794770984863377\n",
      "['53995: Lint: UnusedIds false positive on defined integer', 'Lint: Warn that @android:string/yes returns OK, not Yes', 'integrate https://android-review.googlesource.com/#/c/145848/: add API allowing one RunConfigurationProducer to replace another one (cherry picked from commit 6a3ed85)']\n",
      "android: 164 / 8513 = 0.019264654058498767\n",
      "['aaa: Cannot get administration portal after logging to IPA domain, WFLYEJB0442: Unexpected Error', 'core:refactor: Add IStorageHelper.prepareConnectHostToStoragePoolServers', 'vdsbroker: refactoring: Inject ResourceManager into SpmStopVDSCommand']\n",
      "ovirt: 255 / 7591 = 0.03359241206692135\n",
      "total: 425 / 21191 = 0.020055684016799583\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 2 <= msg.count(':') < 100000, 'more than two \":\"', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: several words before \":\"\n",
      "['Cosmetic change: chain setters', 'Change screen: Make change owner votes removable', 'Fix jdbc code: Both PreparedStatements must be closed in any case']\n",
      "google: 130 / 5087 = 0.02555533713387065\n",
      "['Possible fix for https://code.google.com/p/android/issues/detail?id=152085', 'Align with main: two ways of parsing repeated packable fields.', 'Late binding: track differences in RI behavior']\n",
      "android: 390 / 8513 = 0.045812287090332436\n",
      "['Revert \"engine: Obtain old network name from correct NIC (#849971)\"', 'userportal, webadmin: moved ApplicationResourcesWithLookup', 'Revert \"core: Prevent StopVm to interleave with other VM locked actions\"']\n",
      "ovirt: 110 / 7591 = 0.014490844421024898\n",
      "total: 630 / 21191 = 0.029729602189608795\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 1 <= msg.count(':') < 2 and len(msg.split(':')[0].split()) > 1, 'several words before \":\"', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \"::\" in msg\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: '::' in msg, '\"::\" in msg', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: revert words\n",
      "['Revert \"Workaround Guice bug \"getPathInfo not decoded\"\"', 'Revert \"Fix GWT UI AddFileBox to provide path suggestions continuously\"', 'Revert \"Make VisibleRefFilter.Filter reuse the refs passed from JGit.\"']\n",
      "google: 38 / 5087 = 0.007470021623746805\n",
      "['Revert \"Reverted to Gradle 1.6 due to RMI problem when importing projects.\"', 'Revert \"Revert \"ExpatParser LP64 fixes.\"\"', 'Revert \"HIDL Java getService now the same as C++.\"']\n",
      "android: 210 / 8513 = 0.02466815458710208\n",
      "['Revert \"core: Kernel cmdline - host deploy\"', 'Revert \"engine: Create default network QoS for ovirtmgmt upon DC creation\"', 'core: Revert Delete jobs that their steps have no async-tasks']\n",
      "ovirt: 63 / 7591 = 0.008299301804768806\n",
      "total: 311 / 21191 = 0.014676041715822754\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 1 <= msg.lower().split().count('revert') < 2, 'revert words', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: revert has always unrevert\n",
      "[]\n",
      "google: 0 / 5087 = 0.0\n",
      "[]\n",
      "android: 0 / 8513 = 0.0\n",
      "['Revert \"engine: Create default network QoS for ovirtmgmt upon DC creation\"', 'engine: Create default network QoS for ovirtmgmt upon DC creation', 'Revert \"engine: Create default network QoS for ovirtmgmt upon DC creation\"', 'Revert \"engine: Create default network QoS for ovirtmgmt upon DC creation\"']\n",
      "ovirt: 4 / 7591 = 0.0005269397971281781\n",
      "total: 4 / 21191 = 0.00018875937898164315\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 'engine: Create default network QoS' in msg, 'revert has always unrevert', n_sample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_merge_statistics():\n",
    "    print(f'Merge \":\" statistics')\n",
    "    def get_merge_num(commit_msgs_dict):\n",
    "        with_prefix = [msg for msg in commit_msgs_dict.values() if 'merge' in msg.lower().split()]\n",
    "        # print(random.sample(with_prefix, 5))\n",
    "        return len(with_prefix)\n",
    "    \n",
    "    total_merge_num = 0\n",
    "    total = 0\n",
    "    for project, commit_mgs in COMMIT_MESSAGES.items():\n",
    "        merge_num = get_merge_num(commit_mgs)\n",
    "        total_merge_num += merge_num\n",
    "        total += len(commit_mgs)\n",
    "        print(f'{project}: {merge_num} / {len(commit_mgs)} = {merge_num / len(commit_mgs)}')\n",
    "    print(f'total: {total_merge_num} / {total} = {total_merge_num / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge \":\" statistics\n",
      "google: 168 / 5087 = 0.03302535875761746\n",
      "android: 239 / 8513 = 0.02807470926817808\n",
      "ovirt: 14 / 7591 = 0.0018442892899486233\n",
      "total: 421 / 21191 = 0.019866924637817942\n"
     ]
    }
   ],
   "source": [
    "print_merge_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_do_not_merge_statistics():\n",
    "    print(f'Merge \":\" statistics')\n",
    "    def get_merge_num(commit_msgs_dict):\n",
    "        with_prefix = [msg for msg in commit_msgs_dict.values() if msg.startswith('DO NOT MERGE')]\n",
    "        return len(with_prefix)\n",
    "    \n",
    "    total_merge_num = 0\n",
    "    total = 0\n",
    "    for project, commit_mgs in COMMIT_MESSAGES.items():\n",
    "        merge_num = get_merge_num(commit_mgs)\n",
    "        total_merge_num += merge_num\n",
    "        total += len(commit_mgs)\n",
    "        print(f'{project}: {merge_num} / {len(commit_mgs)} = {merge_num / len(commit_mgs)}')\n",
    "    print(f'total: {total_merge_num} / {total} = {total_merge_num / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge \":\" statistics\n",
      "google: 0 / 5087 = 0.0\n",
      "android: 152 / 8513 = 0.017855045224950076\n",
      "ovirt: 0 / 7591 = 0.0\n",
      "total: 152 / 21191 = 0.00717285640130244\n"
     ]
    }
   ],
   "source": [
    "print_do_not_merge_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like 'merge' word in commit messages is not really a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: do no contain punctuation at all\n",
      "['Remove index defaultMaxClauseCount config setting while reusing maxTerms', 'Set hasChange on index queries depending on schema version', 'Add test for search of an empty topic']\n",
      "google: 2090 / 5087 = 0.4108511893060743\n",
      "['Let voicemail broadcast test pass if not applicable', 'Add property to be able to import malformed jar files', 'Remove verification for DownloadReceiver when failure']\n",
      "android: 2562 / 8513 = 0.30095148596264537\n",
      "['Introduce template diskattachments resources and remove old API', 'Add import template from configuration', 'Report constraint matches when using TestOptimizer']\n",
      "ovirt: 179 / 7591 = 0.02358055592148597\n",
      "total: 4831 / 21191 = 0.2279741399650795\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: len([p for p in string.punctuation if p in msg]) == 0, 'do no contain punctuation at all', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ovirt is very low because of ':'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\\\', '@', '`', '>', ')', '&', '~', '$', '^', ']', '<', '+', '/', '_', '?', '{', '!', '|', '=', '#', ';', '\"', '}', '[', '-', '*', '%', '(', \"'\"}\n"
     ]
    }
   ],
   "source": [
    "MY_PUNCTUATION = set(string.punctuation) - {':', '.', ','}\n",
    "print(MY_PUNCTUATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: do no contain punctuation at all\n",
      "['ChangeScreen2: Respect user preference for unified diff view', 'Extract fetching commit messages into injectable class', 'Reindex account on push to user branch']\n",
      "google: 3237 / 5087 = 0.6363278946333792\n",
      "['Launch new Home app when selecting Home app in Settings', 'SELinuxTest:  Add a few more cases to testFileContexts.', 'Unregister data enabled changed listener on default phone']\n",
      "android: 5650 / 8513 = 0.6636908257958416\n",
      "['webadmin: Hotfix of icon validation for IE', 'core: Make ConfigValuesTest more informative', 'webadmin: display Disk Snapshot ID on cinder domains']\n",
      "ovirt: 5231 / 7591 = 0.689105519694375\n",
      "total: 14118 / 21191 = 0.6662262281157095\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: len([p for p in MY_PUNCTUATION if p in msg]) == 0, 'do no contain punctuation at all', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \".\" is last character\n",
      "['FIX: deep-link into individual commit for non-root URLs.', \"Add ',' to be encoded in email headers.\", 'Allow forcing mergeability check through the REST API.']\n",
      "google: 192 / 5087 = 0.03774326715156281\n",
      "['Make option conflicts less spammy.', 'Fix varargs warnings in harmony tests.', 'gltrace: Show scroll bars.']\n",
      "android: 2943 / 8513 = 0.3457065664278163\n",
      "['core:  QueryData2 generates slow SQL for...', 'engine: Query getdisksvmguid caused postmaster processes to consume constantly 100%cpu.', 'core,webadmin: change switch type default value.']\n",
      "ovirt: 396 / 7591 = 0.052167039915689634\n",
      "total: 3531 / 21191 = 0.1666273417960455\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: msg[-1] == '.', '\".\" is last character', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like we should remove point as last character too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \".\" is not last character\n",
      "[\"Merge branch 'stable-2.14' into stable-2.15\", 'PatchLineCommentsUtil#setCommentRevId(...): Remove unused return value', 'Adapt to the simplified GitReferenceUpdatedListener.Event API']\n",
      "google: 548 / 5087 = 0.10772557499508552\n",
      "['Update ECJ to 4.6M4', 'Bug #201268 android.telecom.cts.RemoteConnectionTest -- testRemoteConnectionVideoCallbacks_CallDataUsage fail', \"41782: Graphical Layout Editor can't handle TabWidget. DO NOT MERGE\"]\n",
      "android: 724 / 8513 = 0.0850463996241043\n",
      "['core: CompatibilityVersionUtils.getEffective() with Supplier<Version>', 'restapi: Do not cast memory.used to int', 'host-deploy: upgrade to apache-sshd 0.11.0']\n",
      "ovirt: 349 / 7591 = 0.04597549729943354\n",
      "total: 1621 / 21191 = 0.07649473833231088\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: '.' in msg and msg[-1] != '.', '\".\" is not last character', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \".\" as end of sentence\n",
      "['web.otherUrls auto-config based on Gerrit SSH/HTTPD URLs.', 'Not displaying the \"Sign Out\" for CLIENT_SSL_CERT_LDAP.', 'Fix flaky test.']\n",
      "google: 195 / 5087 = 0.03833300570080598\n",
      "['Fix a possible NPE when reading bad prop files.', 'Fix ADT build: use new AndroidTargetHash.', 'logcat: Validate regex patterns before creating filters.']\n",
      "android: 3006 / 8513 = 0.3531070128039469\n",
      "['webadmin: Modify minimum threshold of Quota.', 'core+webadmin: Audit log a network error while uploading disk.', 'webadmin: Add storage attributes on import SD.']\n",
      "ovirt: 408 / 7591 = 0.05374785930707417\n",
      "total: 3609 / 21191 = 0.17030814968618754\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: '. ' in msg or msg[-1] == '.', '\".\" as end of sentence', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: \"...\" in sentence\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: '...' in msg, '\"...\" in sentence', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_punc_frequency():\n",
    "    def print_freq_for_p(p):\n",
    "        print()\n",
    "        print_after_filtering(lambda msg: p in msg, f'frequency for {p}', n_sample=3)\n",
    "    \n",
    "    for p in string.punctuation:\n",
    "        print_freq_for_p(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering: frequency for !\n",
      "\n",
      "Filtering: frequency for \"\n",
      "['Not displaying the \"Sign Out\" for CLIENT_SSL_CERT_LDAP.', 'Fix z-index of \"session expired\" dialog', 'Fix RpcStatus to display \"Working...\" when header is hidden']\n",
      "google: 178 / 5087 = 0.03499115392176135\n",
      "['Merge \"DO NOT MERGE: Test for bug 33137046\" into nougat-cts-dev am: 38465d5435  -s ours', 'Add dalvik subitems for -d in dumpsys meminfo \"Total PSS by category\"', 'Revert \"java.time.Instant.toEpochMilli() fixes\"']\n",
      "android: 429 / 8513 = 0.05039351579936568\n",
      "['restapi: Always use \"general\" value of VdcFenceOptionTypes', 'core: Clear current SPM upon \"Not SPM\" error', 'core: Use \"Integer.parseInt\" in \"VmHandler\"']\n",
      "ovirt: 204 / 7591 = 0.026873929653537083\n",
      "total: 811 / 21191 = 0.03827096408852815\n",
      "\n",
      "Filtering: frequency for #\n",
      "['VersionedMetaData#load: Use provided RevWalk instead of creating a new one', 'Avoid long overflow in AccessToken#isExpired()', 'VersionedMetaData#updateRef: Use passed newId value']\n",
      "google: 115 / 5087 = 0.022606644387654806\n",
      "[\"80223: Don't flag SwipeRefreshLayouts#setProgressBackgroundColor(R.color.id)\", 'Revert \"Revert \"Fix DatagramChannelTest#test_setOption.\"\"', 'Move InetAddress#isReachable away from JNI']\n",
      "android: 208 / 8513 = 0.02443321978151063\n",
      "['core: TicketingTest#testNoRepeats as @RepeatedTest', 'core: Rename VmHandler#getVmInitByIds', 'core: fixed NPE during removal of floating disk (#845046)']\n",
      "ovirt: 328 / 7591 = 0.0432090633645106\n",
      "total: 651 / 21191 = 0.030720588929262424\n",
      "\n",
      "Filtering: frequency for $\n",
      "\n",
      "Filtering: frequency for %\n",
      "\n",
      "Filtering: frequency for &\n",
      "\n",
      "Filtering: frequency for '\n",
      "[\"Merge branch 'stable-2.11'\", \"Merge branch 'stable-2.15'\", \"Use HistogramDiff when computing 'Commit Message'\"]\n",
      "google: 587 / 5087 = 0.1153921761352467\n",
      "['Fix for checkKernelWakelock function : It contains a comma character in the \"Kernel Wakelock\". So When parts arr\\'s length is more than 7, Fix check routine.', \"Merge commit '5fa2972939fbeb5b3691db2762a7c7eb1ecce74c' into nougat-mr1-cts-dev\", \"DO NOT MERGE: Camera: don't always require ZSL template\"]\n",
      "android: 393 / 8513 = 0.046164689298719606\n",
      "[\"core: resouces of VMs in launch state shouldn't be committed\", \"webadmin: Add Users and Groups dialog: cannot close via 'X' button or Esc key\", \"webadmin: tiny fix for make template dialog's focus traversal\"]\n",
      "ovirt: 409 / 7591 = 0.05387959425635621\n",
      "total: 1389 / 21191 = 0.06554669435137558\n",
      "\n",
      "Filtering: frequency for (\n",
      "['Fix non-ascii password authentication failure under tomcat (LDAP)', 'Swap the order of resources in writeToResponse()', 'Fix: EditCommitMessage (PatchSetInserter changed arguments)']\n",
      "google: 185 / 5087 = 0.03636721053666208\n",
      "[\"Avoid Calendar's unexpect change in snapToCycleDay()\", 'Add min_ce/max_ce parameters to requestLeConnectionUpdate()', 'Safely handle interrupts during Thread.join()']\n",
      "android: 457 / 8513 = 0.053682603077645955\n",
      "['userportal, webadmin: add ko-KR locale (part 1)', 'webadmin: disabling host address in host dialog(#829844)', 'core: Remove vm succeeds even though one of the images is located on domain in maintenance (#827908)']\n",
      "ovirt: 347 / 7591 = 0.04571202740086945\n",
      "total: 989 / 21191 = 0.04667075645321127\n",
      "\n",
      "Filtering: frequency for )\n",
      "['Support for Source compressed download (ZIP, GZ).', 'AccountSshKey.Id: Add isValid() method', 'Add JS Gerrit.on() hook on opening change screen']\n",
      "google: 185 / 5087 = 0.03636721053666208\n",
      "['Use TextUtils.isEmpty() instead of null check.', 'OpenSSLX509CertPath: add null check in fromEncoding(InputStream)', 'Ensure method is JITted (or compiled).']\n",
      "android: 455 / 8513 = 0.05344766827205451\n",
      "['core: allow upgrading cluster level when there are running VMs (#856172)', 'core: disk_image_dynamic statistics (#892596)', 'core: java.lang.reflect.InvocationTargetException when removing vm and exporting it at the same time: Race (#840418)']\n",
      "ovirt: 347 / 7591 = 0.04571202740086945\n",
      "total: 987 / 21191 = 0.04657637676372045\n",
      "\n",
      "Filtering: frequency for *\n",
      "\n",
      "Filtering: frequency for +\n",
      "\n",
      "Filtering: frequency for ,\n",
      "[\"Strings are immutable, field should be named 'INBOX_FOLDER'\", 'When testing, be explicit for which projects to throw exception', 'cat, ls: move inside our main program package']\n",
      "google: 86 / 5087 = 0.016905838411637508\n",
      "['BaseBlockCipher: for BCEPBEKeys, ignore parameters if no IV is present', 'When IMS connections are merged, track connect time elapsed.', 'DO NOT MERGE, re-apply, Adjust testAppFailAccessPrivateData to fail on non-tagged sockets']\n",
      "android: 231 / 8513 = 0.027134970045812286\n",
      "['webadmin,userportal: Clean up Editor fields before Model objects', 'core: ListUtils#listsEqual(Collection, Collection)', 'userportal, webadmin: Make ElementTooltip.setContent() null-safe']\n",
      "ovirt: 200 / 7591 = 0.026346989856408907\n",
      "total: 517 / 21191 = 0.024397149733377376\n",
      "\n",
      "Filtering: frequency for -\n",
      "[\"Merge branch 'master' into stable-2.11\", 'Double-check change data in cleaning up task', \"Merge branch 'stable-2.12' into master\"]\n",
      "google: 698 / 5087 = 0.13721250245724395\n",
      "['Trim the mime type portion of Content-Type.', 'Reduce the number of dumps in 130-hprof.', \"Don't replace file extension when mime-type is incorrect\"]\n",
      "android: 968 / 8513 = 0.11370844590626102\n",
      "['Revert \"engine: add finish report on multi-host network commands\"', 'java: fix typo recieved -> received', 'core: DeactivateStorageDomainWithOvfUpdate - locks']\n",
      "ovirt: 938 / 7591 = 0.12356738242655776\n",
      "total: 2604 / 21191 = 0.1228823557170497\n",
      "\n",
      "Filtering: frequency for .\n",
      "['Fix notes NPE for has:draft search predicate.', 'Use isNullOrEmpty, JUnit4.RunWith, and remove toString', 'Upgrade wiremock to version 2.5.1']\n",
      "google: 740 / 5087 = 0.14546884214664832\n",
      "['Revert \"Fix resource leaks.\"', 'Import settings for 1.4 preview from 1.3 final.', 'When IMS connections are merged, track connect time elapsed.']\n",
      "android: 3667 / 8513 = 0.4307529660519206\n",
      "['Match Host.Ping with equals and not ==', 'frontend: Fix SearchableListModel.getSearchString()', 'core:refactor: Add IStorageHelper.prepareConnectHostToStoragePoolServers']\n",
      "ovirt: 745 / 7591 = 0.09814253721512317\n",
      "total: 5152 / 21191 = 0.24312208012835637\n",
      "\n",
      "Filtering: frequency for /\n",
      "['Set commit ID in result of the /changes/*/revisions/*/commit endpoint', 'Update EncryptedContactStore to not use deprecated/removed methods', 'Rest API, add GET /past_assigness endpoint for historical assignees']\n",
      "google: 251 / 5087 = 0.0493414586200118\n",
      "['Fix issue where there could be variants w/ no outputs.', 'Fix moving GC bugs in proxy stub for X86/X86_64', 'Fix Build: DragSourceEvent has no offsetX/Y in SWT 3.4']\n",
      "android: 337 / 8513 = 0.03958651474215905\n",
      "['core: Add Africa/Algiers Time Zone', 'gluster: VDS Cmd - Gluster volume snapshot activate/de-activate', 'webadmin: display all alerts/events']\n",
      "ovirt: 135 / 7591 = 0.01778421815307601\n",
      "total: 723 / 21191 = 0.034118257750931996\n",
      "\n",
      "Filtering: frequency for :\n",
      "['AdminQueryShell: Reduce scope of try-catch to necessary calls', 'Lucene: Use stored ChangedLines values', 'Set Access-Control-Allow-Origin: * on API requests']\n",
      "google: 1387 / 5087 = 0.27265578926675843\n",
      "['OPP: Add local support for file transfer error text.', 'CTS: Device with UI mode set to VR_HEADSET is identified as a watch', 'Gradle: fix compatibility with Gradle 2.0 (cherry picked from commit 84cd616)']\n",
      "android: 1797 / 8513 = 0.21108892282391636\n",
      "['engine: Remove unused code', 'webadmin: Add default description to multiple action result', 'core: Fix LunDao#removeAll']\n",
      "ovirt: 7305 / 7591 = 0.9623238045053353\n",
      "total: 10489 / 21191 = 0.49497428153461376\n",
      "\n",
      "Filtering: frequency for ;\n",
      "\n",
      "Filtering: frequency for <\n",
      "\n",
      "Filtering: frequency for =\n",
      "\n",
      "Filtering: frequency for >\n",
      "\n",
      "Filtering: frequency for ?\n",
      "\n",
      "Filtering: frequency for @\n",
      "['core: @Inject GetDiskProfileByIdQuery Daos', 'core: @Inject GetNetworkLabelsByHostNicIdQuery Daos', 'core: @Inject GetVnicProfilesByNetworkIdQuery Daos']\n",
      "ovirt: 202 / 7591 = 0.026610459754972993\n",
      "total: 286 / 21191 = 0.013496295597187485\n",
      "\n",
      "Filtering: frequency for [\n",
      "['[cts] Fix UsesLibraryTest', 'Java support for passing vec<STRUCT-TYPE> and STRUCT-TYPE[] to and from methods.', '[RenderScript] (minor) fix validation of L3 BLAS']\n",
      "android: 160 / 8513 = 0.01879478444731587\n",
      "\n",
      "Filtering: frequency for \\\n",
      "\n",
      "Filtering: frequency for ]\n",
      "['[NAN] Fix incorrect log message', '[CTS]It should be more reasonable to use setBatterySaverMode API to leave power-save mode instead of plugging in charger for \"CtsHostsideNetworkTests\" test case.', '[automerger skipped] DO NOT MERGE CTS for presence of avc fix for b/70897454 am: 8a0f955e56  -s ours']\n",
      "android: 158 / 8513 = 0.01855984964172442\n",
      "\n",
      "Filtering: frequency for ^\n",
      "\n",
      "Filtering: frequency for _\n",
      "['SitePaths.etc_dir from File to Path Compilation errors.', 'Hide RefControl.canSubmit, adding UPDATE_BY_SUBMIT', 'Include the total_size of a namespace in the REST response']\n",
      "google: 145 / 5087 = 0.028504029880086493\n",
      "['Check for null column before getting contact_id', \"Don't check that root owns procfs mmap_rnd_bits\", 'Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()']\n",
      "android: 405 / 8513 = 0.047574298132268295\n",
      "['aaa: AuthRecord.VALID_TO should be Z timezone', 'webadmin: Cluster dialog - ja_JP locale adjustment', 'core: Fix fixtures schema for vm_interface_statistics']\n",
      "ovirt: 168 / 7591 = 0.02213147147938348\n",
      "total: 718 / 21191 = 0.033882308527204946\n",
      "\n",
      "Filtering: frequency for `\n",
      "\n",
      "Filtering: frequency for {\n",
      "\n",
      "Filtering: frequency for |\n",
      "\n",
      "Filtering: frequency for }\n",
      "\n",
      "Filtering: frequency for ~\n"
     ]
    }
   ],
   "source": [
    "print_punc_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Added',\n",
       " 'CLOSED_INBOUND',\n",
       " 'and',\n",
       " 'CLOSED_OUTBOUND',\n",
       " 'states',\n",
       " 'to',\n",
       " 'OpenSSLEngineImpl',\n",
       " '#',\n",
       " 'getHandshakeStatus',\n",
       " '(',\n",
       " ')']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('Added CLOSED_INBOUND and CLOSED_OUTBOUND states to OpenSSLEngineImpl#getHandshakeStatus()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that these changes have only one change in method for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_urls_for_project(project, n_sample):\n",
    "    print([CSV_DATA['URL'][IND_TO_ROW[project][i]] for i in random.sample(LIST_OF_SINGLE_CHANGED_FILES[project], n_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['android-review.googlesource.com/c/123111', 'android-review.googlesource.com/c/400852', 'android-review.googlesource.com/c/231511', 'android-review.googlesource.com/c/166181', 'android-review.googlesource.com/c/681962', 'android-review.googlesource.com/c/15460', 'android-review.googlesource.com/c/114946', 'android-review.googlesource.com/c/14917', 'android-review.googlesource.com/c/115814', 'android-review.googlesource.com/c/623828']\n"
     ]
    }
   ],
   "source": [
    "sample_urls_for_project('android', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gerrit-review.googlesource.com/c/121070', 'gerrit-review.googlesource.com/c/47913', 'gerrit-review.googlesource.com/c/148150', 'gerrit-review.googlesource.com/c/72787', 'gerrit-review.googlesource.com/c/74469', 'gerrit-review.googlesource.com/c/71697', 'gerrit-review.googlesource.com/c/112210', 'gerrit-review.googlesource.com/c/30016', 'gerrit-review.googlesource.com/c/79981', 'gerrit-review.googlesource.com/c/6723']\n"
     ]
    }
   ],
   "source": [
    "sample_urls_for_project('google', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gerrit.ovirt.org/c/60884', 'gerrit.ovirt.org/c/69607', 'gerrit.ovirt.org/c/10990', 'gerrit.ovirt.org/c/6318', 'gerrit.ovirt.org/c/40423', 'gerrit.ovirt.org/c/9126', 'gerrit.ovirt.org/c/34955', 'gerrit.ovirt.org/c/30998', 'gerrit.ovirt.org/c/18664', 'gerrit.ovirt.org/c/63158']\n"
     ]
    }
   ],
   "source": [
    "sample_urls_for_project('ovirt', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I took a look at those PRs. Most of the methods which were changed are big enough. Therefore I have big doubts about final size of dataset. Also approximately a half of PRs contained more than one file changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: msgs with numbers\n",
      "['Upgrade gerrit plugin api to 2.11.1', 'Update H2 to 1.2.134', 'Improve LDAP login times, transfer 40x less data.']\n",
      "google: 486 / 5087 = 0.09553764497739335\n",
      "['resolve merge conflicts of 1cf3c1dd2a to nougat-mr1-cts-dev', 'Revert \"Add regression tests for 32-bit x86 struct layout bug fixes.\"', 'Merge \"DO NOT MERGE: Fix VrDisplayTest\" into oreo-cts-dev am: 92d3cbf146  -s ours']\n",
      "android: 1315 / 8513 = 0.1544696346763773\n",
      "[\"core: Improve VmDevice's toString (#851991)\", 'core: report 0 on negative values in maxSchedulingMemory', 'engine: Unit tests fail in non-English locale (#1171139)']\n",
      "ovirt: 437 / 7591 = 0.057568172836253456\n",
      "total: 2238 / 21191 = 0.10561087254022934\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: len([w for w in msg.split() if len([str(i) for i in range(10) if str(i) in w]) != 0]) != 0, 'msgs with numbers', n_sample=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final decisions: we should remove the whole prefix before \":\", we should remove \".\" if it is the last character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Close', 'DirContext', 'context', 'in', 'LdapRealm', ':', ':isActive']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('Close DirContext context in LdapRealm::isActive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['integrate',\n",
       " 'https',\n",
       " ':',\n",
       " '//android-review.googlesource.com/',\n",
       " '#',\n",
       " '/c/145848/',\n",
       " ':',\n",
       " 'add',\n",
       " 'API',\n",
       " 'allowing',\n",
       " 'one',\n",
       " 'RunConfigurationProducer',\n",
       " 'to',\n",
       " 'replace',\n",
       " 'another',\n",
       " 'one',\n",
       " '(',\n",
       " 'cherry',\n",
       " 'picked',\n",
       " 'from',\n",
       " 'commit',\n",
       " '6a3ed85',\n",
       " ')']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('integrate https://android-review.googlesource.com/#/c/145848/: add API allowing one RunConfigurationProducer to replace another one (cherry picked from commit 6a3ed85)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unabstracted_cmg_dataset():\n",
    "    from shutil import copyfile\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + 'datasets/cmg_unabstracted/ids.txt', 'w') as ids_file, \\\n",
    "         open(root + 'datasets/cmg_unabstracted/msgs.txt', 'w') as msgs_file:\n",
    "        ids_to_write = []\n",
    "        msgs_to_write = []\n",
    "        for project, pr_ids in LIST_OF_SINGLE_CHANGED_FILES.items():\n",
    "            for pr_id in pr_ids:\n",
    "                if pr_id not in IND_TO_ROW[project].keys():\n",
    "                    print(f'{pr_id} not found in csv for project {project}, it will be skipped')\n",
    "                    continue\n",
    "                ids_to_write.append(str(IND_TO_ROW[project][pr_id]))\n",
    "                assert(len(COMMIT_MESSAGES[project][pr_id].splitlines()) == 1)\n",
    "                msgs_to_write.append(COMMIT_MESSAGES[project][pr_id])\n",
    "                cur_id = len(ids_to_write)\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/before.java', root + f'datasets/cmg_unabstracted/prev/{cur_id}.java')\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/after.java', root + f'datasets/cmg_unabstracted/updated/{cur_id}.java')\n",
    "        ids_file.write('\\n'.join(ids_to_write))\n",
    "        msgs_file.write('\\n'.join(msgs_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664242 not found in csv for project android, it will be skipped\n",
      "688460 not found in csv for project android, it will be skipped\n"
     ]
    }
   ],
   "source": [
    "generate_unabstracted_cmg_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: merge\n",
      "['Display hash of the cherry-pick merge in comment', 'Fix: Gerrit cannot display Change with non-resolvable Merge Commit', \"Merge branch 'stable-2.11'\"]\n",
      "google: 168 / 5087 = 0.03302535875761746\n",
      "['resolve merge conflicts of f15f0ef to gradle-dev.', 'DO NOT MERGE Remove docked stack size assertion', 'resolve merge conflicts of 4b2496ba197fb161dd35cb3956211d3dd3ef5e3f to oreo-mr1-vts-dev']\n",
      "android: 239 / 8513 = 0.02807470926817808\n",
      "total: 421 / 21191 = 0.019866924637817942\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: 'merge' in msg.lower().split(), 'merge', n_sample=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's remove merge commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unabstracted_cmg_dataset_with_removed_merge_commits():\n",
    "    from shutil import copyfile\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + 'datasets/cmg_unabstracted_without_merge_commits/ids.txt', 'w') as ids_file, \\\n",
    "         open(root + 'datasets/cmg_unabstracted_without_merge_commits/msgs.txt', 'w') as msgs_file:\n",
    "        ids_to_write = []\n",
    "        msgs_to_write = []\n",
    "        skipped_merge = 0\n",
    "        for project, pr_ids in LIST_OF_SINGLE_CHANGED_FILES.items():\n",
    "            for pr_id in pr_ids:\n",
    "                if pr_id not in IND_TO_ROW[project].keys():\n",
    "                    print(f'{pr_id} not found in csv for project {project}, it will be skipped')\n",
    "                    continue\n",
    "                msg = COMMIT_MESSAGES[project][pr_id]\n",
    "                if 'merge' in msg.lower().split():\n",
    "                    skipped_merge += 1\n",
    "                    continue\n",
    "                ids_to_write.append(str(IND_TO_ROW[project][pr_id]))\n",
    "                assert(len(msg.splitlines()) == 1)\n",
    "                msgs_to_write.append(msg)\n",
    "                cur_id = len(ids_to_write)\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/before.java', root + f'datasets/cmg_unabstracted_without_merge_commits/prev/{cur_id}.java')\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/after.java', root + f'datasets/cmg_unabstracted_without_merge_commits/updated/{cur_id}.java')\n",
    "        ids_file.write('\\n'.join(ids_to_write))\n",
    "        msgs_file.write('\\n'.join(msgs_to_write))\n",
    "        print(f'Skipped merge commits: {skipped_merge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664242 not found in csv for project android, it will be skipped\n",
      "688460 not found in csv for project android, it will be skipped\n",
      "Skipped merge commits: 421\n"
     ]
    }
   ],
   "source": [
    "generate_unabstracted_cmg_dataset_with_removed_merge_commits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons():\n",
    "    from shutil import copyfile\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + 'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons/ids.txt', 'w') as ids_file, \\\n",
    "         open(root + 'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons/msgs.txt', 'w') as msgs_file:\n",
    "        ids_to_write = []\n",
    "        msgs_to_write = []\n",
    "        skipped_merge = 0\n",
    "        skipped_colons = 0\n",
    "        for project, pr_ids in LIST_OF_SINGLE_CHANGED_FILES.items():\n",
    "            for pr_id in pr_ids:\n",
    "                if pr_id not in IND_TO_ROW[project].keys():\n",
    "                    print(f'{pr_id} not found in csv for project {project}, it will be skipped')\n",
    "                    continue\n",
    "                msg = COMMIT_MESSAGES[project][pr_id]\n",
    "                if 'merge' in msg.lower().split():\n",
    "                    skipped_merge += 1\n",
    "                    continue\n",
    "                if len(msg.split(': ')) > 2:\n",
    "                    skipped_colons += 1\n",
    "                    continue\n",
    "                ids_to_write.append(str(IND_TO_ROW[project][pr_id]))\n",
    "                assert(len(msg.splitlines()) == 1)\n",
    "                msgs_to_write.append(msg)\n",
    "                cur_id = len(ids_to_write)\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/before.java', root + f'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons/prev/{cur_id}.java')\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/after.java', root + f'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons/updated/{cur_id}.java')\n",
    "        ids_file.write('\\n'.join(ids_to_write))\n",
    "        msgs_file.write('\\n'.join(msgs_to_write))\n",
    "        print(f'Skipped merge commits: {skipped_merge}')\n",
    "        print(f'Skipped colons: {skipped_colons}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664242 not found in csv for project android, it will be skipped\n",
      "688460 not found in csv for project android, it will be skipped\n",
      "Skipped merge commits: 421\n",
      "Skipped colons: 334\n"
     ]
    }
   ],
   "source": [
    "generate_unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering: merge\n",
      "['Use Tested-by: instead of Verified-by: during cherry-pick', 'Make bug: an alias for tr: in search']\n",
      "google: 2 / 5087 = 0.00039315903282877927\n",
      "['Android patch: CLDR ticket #7969: Percent formatting in RTL text.', 'Merge \"DO NOT MERGE: Crop the real height of status bar when taking preference screenshot\" into oreo-cts-dev am: a6be3b7154  -s ours', 'DO NOT MERGE: CTS test for fix of b/65717533 am: 50d956befd  -s ours']\n",
      "android: 132 / 8513 = 0.015505697169035593\n",
      "['core: framework: add domain processor pre-processor', 'utils: LocalConfig: support empty file names', 'sercon: servlet: db: send correct login name']\n",
      "ovirt: 234 / 7591 = 0.03082597813199842\n",
      "total: 368 / 21191 = 0.01736586286631117\n"
     ]
    }
   ],
   "source": [
    "print_after_filtering(lambda msg: msg.count(': ') > 1, 'merge', n_sample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_prefix_colon(msg):\n",
    "    assert(len(msg.split(': ')) <= 2)\n",
    "    if ':' in msg and len(msg.split(': ')) == 1 and len(msg.split(':')[0].split()) == 1:\n",
    "        return msg.split(':')[-1]\n",
    "    return msg.split(': ')[-1]\n",
    "\n",
    "def preprocess_suffix_punctuation(msg):\n",
    "    if msg.endswith('.'):\n",
    "        return msg[:-1]\n",
    "    elif msg.endswith('...'):\n",
    "        print(msg)\n",
    "        print(msg[:-3])\n",
    "        assert(False)\n",
    "        return msg[:-3]\n",
    "    return msg\n",
    "\n",
    "def preprocess_msg(msg):\n",
    "    msg = preprocess_prefix_colon(msg)\n",
    "    msg = preprocess_suffix_punctuation(msg)\n",
    "    return msg\n",
    "    \n",
    "def preprocess_msgs(dataset_folder_name):\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + f'datasets/{dataset_folder_name}/msgs.txt', 'r') as msgs_file, \\\n",
    "         open(root + f'datasets/{dataset_folder_name}/msgs_preprocessed.txt', 'w') as msgs_preprocessed_file:\n",
    "        preprocessed_msgs = [preprocess_msg(msg.strip()) for msg in msgs_file]\n",
    "        msgs_preprocessed_file.write('\\n'.join(preprocessed_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Removed console tab from new/edit cluster popup in gluster only mode'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_msg('webadmin:Removed console tab from new/edit cluster popup in gluster only mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_msgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction():\n",
    "    from shutil import copyfile\n",
    "    import os\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + 'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction/ids.txt', 'w') as ids_file, \\\n",
    "         open(root + 'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction/msgs.txt', 'w') as msgs_file:\n",
    "        ids_to_write = []\n",
    "        msgs_to_write = []\n",
    "        skipped_merge = 0\n",
    "        skipped_colons = 0\n",
    "        for project, pr_ids in LIST_OF_SINGLE_CHANGED_FILES.items():\n",
    "            for pr_id in pr_ids:\n",
    "                if pr_id not in IND_TO_ROW[project].keys():\n",
    "                    print(f'{pr_id} not found in csv for project {project}, it will be skipped')\n",
    "                    continue\n",
    "                msg = COMMIT_MESSAGES[project][pr_id]\n",
    "                if 'merge' in msg.lower().split():\n",
    "                    skipped_merge += 1\n",
    "                    continue\n",
    "                if len(msg.split(': ')) > 2:\n",
    "                    skipped_colons += 1\n",
    "                    continue\n",
    "                ids_to_write.append(str(IND_TO_ROW[project][pr_id]))\n",
    "                assert(len(msg.splitlines()) == 1)\n",
    "                msgs_to_write.append(msg)\n",
    "                cur_id = len(ids_to_write)\n",
    "                root_of_sample = root + f'datasets/unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction/{cur_id}/'\n",
    "                os.mkdir(root_of_sample)\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/before.java', root_of_sample + 'prev_method.java')\n",
    "                copyfile(root + f'{project}/{pr_id}/0/0/after.java', root_of_sample + 'updated_method.java')\n",
    "        ids_file.write('\\n'.join(ids_to_write))\n",
    "        msgs_file.write('\\n'.join(msgs_to_write))\n",
    "        print(f'Skipped merge commits: {skipped_merge}')\n",
    "        print(f'Skipped colons: {skipped_colons}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664242 not found in csv for project android, it will be skipped\n",
      "688460 not found in csv for project android, it will be skipped\n",
      "Skipped merge commits: 421\n",
      "Skipped colons: 334\n"
     ]
    }
   ],
   "source": [
    "generate_unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_msgs('unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_abstracted_code(dataset_folder_name, new_dataset_folder_name):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + f'datasets/{new_dataset_folder_name}/prev.txt', 'w') as prev_file, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/updated.txt', 'w') as updated_file, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/msgs.txt', 'r') as msgs_file, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/ids.txt', 'r') as ids_file, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/msgs_new.txt', 'w') as msgs_file_new, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/ids_new.txt', 'w') as ids_file_new, \\\n",
    "         open(root + f'datasets/{new_dataset_folder_name}/folder_names.txt', 'w') as folder_names:\n",
    "        lines_prev = []\n",
    "        lines_updated = []\n",
    "        errored_skipped = 0\n",
    "        msgs_lines = msgs_file.readlines()\n",
    "        ids_lines = ids_file.readlines()\n",
    "        new_msgs = []\n",
    "        new_ids = []\n",
    "        idx = sorted([int(i) for i in os.listdir(root + f'datasets/{dataset_folder_name}') if not i.endswith('.txt')])\n",
    "        for i in idx:\n",
    "            prev = Path(root + f'datasets/{dataset_folder_name}/{i}/abstracted/prev.txt').read_text().strip()\n",
    "            updated = Path(root + f'datasets/{dataset_folder_name}/{i}/abstracted/updated.txt').read_text().strip()\n",
    "            if prev == '<ERROR>':\n",
    "                print(f'Skipped {i} because of error')\n",
    "                errored_skipped += 1\n",
    "                continue\n",
    "            lines_prev.append(prev)\n",
    "            lines_updated.append(updated)\n",
    "            new_msgs.append(msgs_lines[i - 1].strip())\n",
    "            new_ids.append(ids_lines[i - 1].strip())\n",
    "            folder_names.write(f'{i}\\n')\n",
    "        prev_file.write('\\n'.join(lines_prev))\n",
    "        updated_file.write('\\n'.join(lines_updated))\n",
    "        msgs_file_new.write('\\n'.join(new_msgs))\n",
    "        ids_file_new.write('\\n'.join(new_ids))\n",
    "        print(f'Total skipped: {errored_skipped} / {20436} = {errored_skipped / 20436}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 6792 because of error\n",
      "Skipped 8230 because of error\n",
      "Skipped 8577 because of error\n",
      "Skipped 8675 because of error\n",
      "Skipped 8690 because of error\n",
      "Skipped 8899 because of error\n",
      "Skipped 8982 because of error\n",
      "Skipped 9065 because of error\n",
      "Skipped 9669 because of error\n",
      "Skipped 9708 because of error\n",
      "Skipped 9932 because of error\n",
      "Skipped 9982 because of error\n",
      "Skipped 10163 because of error\n",
      "Skipped 10682 because of error\n",
      "Skipped 11029 because of error\n",
      "Skipped 11057 because of error\n",
      "Skipped 11325 because of error\n",
      "Skipped 11372 because of error\n",
      "Skipped 11386 because of error\n",
      "Skipped 11530 because of error\n",
      "Skipped 11688 because of error\n",
      "Skipped 11738 because of error\n",
      "Skipped 11788 because of error\n",
      "Skipped 12288 because of error\n",
      "Skipped 12586 because of error\n",
      "Skipped 13062 because of error\n",
      "Total skipped: 26 / 20436 = 0.001272264631043257\n"
     ]
    }
   ],
   "source": [
    "collect_abstracted_code('unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction', 'final_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_messages(dataset_folder_name):\n",
    "    import os\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + f'datasets/{dataset_folder_name}/msgs_new.txt', 'r') as msg_file, \\\n",
    "         open(root + f'datasets/{dataset_folder_name}/msg_tokenized.txt', 'w') as msg_new_file:\n",
    "        tokenized_msgs = [' '.join(word_tokenize(msg.strip())) for msg in msg_file]\n",
    "        msg_new_file.write('\\n'.join(tokenized_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_messages('final_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_messages(dataset_folder_name, dataset_folder_name_mapping):\n",
    "    import os\n",
    "    \n",
    "    def read_mapping(folder_name):\n",
    "        with open(root + f'datasets/{dataset_folder_name_mapping}/{folder_name}/abstracted/mapping.txt', 'r') as mapping_file:\n",
    "            mapping = {}\n",
    "            i = 0\n",
    "            mapping_lines = [l.strip() for l in mapping_file]\n",
    "            while i < len(mapping_lines) and mapping_lines[i] != '':\n",
    "                keys = mapping_lines[i].split(',')[:-1]\n",
    "                values = mapping_lines[i + 1].split(',')[:-1]\n",
    "                mapping.update(zip(keys, values))\n",
    "                i += 2\n",
    "        return mapping\n",
    "    \n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + f'datasets/{dataset_folder_name}/msg_tokenized.txt', 'r') as msg_file, \\\n",
    "         open(root + f'datasets/{dataset_folder_name}/msg_abstract.txt', 'w') as msg_new_file, \\\n",
    "         open(root + f'datasets/{dataset_folder_name}/folder_names.txt', 'r') as folder_names:\n",
    "        abstracted_msgs = []\n",
    "        msg_lines = [l.strip() for l in msg_file]\n",
    "        folder_names_lines = [l.strip() for l in folder_names]\n",
    "        i = 1\n",
    "        changed_lines = []\n",
    "        for msg, folder_name in zip(msg_lines, folder_names_lines):\n",
    "            mapping = read_mapping(folder_name)\n",
    "            abstracted_msg = []\n",
    "            number_of_mapped = 0\n",
    "            for t in msg.split(' '):\n",
    "                if t in mapping and t.lower() != t:\n",
    "                    abstracted_msg.append(mapping[t])\n",
    "                    number_of_mapped += 1\n",
    "                else:\n",
    "                    abstracted_msg.append(t)\n",
    "            if number_of_mapped > 0:\n",
    "                changed_lines.append(i)\n",
    "            abstracted_msgs.append(' '.join(abstracted_msg))\n",
    "            i += 1\n",
    "        msg_new_file.write('\\n'.join(abstracted_msgs))\n",
    "        print(f'Msg changed: {len(changed_lines)} / {len(msg_lines)} = {len(changed_lines) / len(msg_lines)}')\n",
    "        print(changed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Msg changed: 1223 / 20410 = 0.05992160705536502\n",
      "[20, 22, 25, 57, 58, 67, 78, 80, 89, 99, 114, 162, 175, 201, 218, 244, 256, 267, 305, 310, 321, 333, 345, 351, 360, 371, 377, 390, 393, 423, 427, 429, 434, 438, 442, 459, 488, 508, 560, 562, 575, 579, 605, 622, 624, 625, 629, 637, 640, 666, 669, 691, 695, 719, 740, 742, 749, 751, 799, 809, 819, 821, 847, 864, 891, 908, 915, 936, 942, 966, 983, 990, 993, 1010, 1018, 1027, 1048, 1052, 1072, 1081, 1114, 1131, 1134, 1137, 1149, 1182, 1190, 1196, 1197, 1206, 1235, 1251, 1259, 1263, 1281, 1295, 1296, 1299, 1305, 1307, 1308, 1317, 1336, 1339, 1343, 1352, 1354, 1360, 1364, 1378, 1381, 1396, 1406, 1411, 1426, 1435, 1479, 1489, 1502, 1524, 1525, 1533, 1540, 1566, 1572, 1574, 1587, 1591, 1593, 1596, 1619, 1630, 1639, 1654, 1655, 1672, 1697, 1698, 1735, 1745, 1789, 1802, 1812, 1814, 1817, 1818, 1825, 1835, 1838, 1842, 1860, 1867, 1876, 1898, 1915, 1935, 1958, 2001, 2004, 2025, 2029, 2054, 2071, 2097, 2098, 2111, 2127, 2137, 2140, 2156, 2165, 2184, 2186, 2197, 2243, 2248, 2252, 2260, 2283, 2296, 2298, 2309, 2360, 2366, 2376, 2399, 2437, 2460, 2462, 2504, 2512, 2533, 2538, 2562, 2570, 2590, 2645, 2653, 2657, 2666, 2693, 2694, 2696, 2697, 2698, 2711, 2715, 2721, 2725, 2731, 2736, 2757, 2782, 2802, 2813, 2824, 2831, 2840, 2853, 2855, 2859, 2862, 2883, 2887, 2889, 2908, 2929, 2952, 2961, 2965, 2974, 2978, 2981, 2990, 2996, 3007, 3016, 3020, 3030, 3037, 3038, 3085, 3094, 3099, 3104, 3106, 3107, 3119, 3134, 3174, 3182, 3184, 3187, 3213, 3229, 3240, 3248, 3257, 3274, 3294, 3295, 3328, 3340, 3361, 3367, 3384, 3411, 3416, 3426, 3437, 3458, 3461, 3462, 3495, 3507, 3530, 3537, 3539, 3557, 3558, 3571, 3577, 3585, 3592, 3608, 3613, 3632, 3660, 3661, 3662, 3672, 3692, 3719, 3745, 3748, 3791, 3817, 3823, 3828, 3864, 3894, 3917, 3921, 3924, 3940, 3942, 3943, 3948, 3974, 3985, 3993, 3995, 4001, 4009, 4019, 4021, 4034, 4037, 4045, 4046, 4050, 4066, 4087, 4120, 4121, 4135, 4142, 4156, 4173, 4222, 4223, 4224, 4230, 4232, 4234, 4236, 4237, 4275, 4305, 4311, 4345, 4382, 4387, 4399, 4401, 4415, 4417, 4441, 4448, 4458, 4459, 4460, 4471, 4482, 4489, 4490, 4501, 4524, 4542, 4554, 4563, 4565, 4567, 4570, 4578, 4580, 4594, 4596, 4610, 4615, 4627, 4642, 4649, 4653, 4677, 4678, 4687, 4696, 4700, 4704, 4705, 4722, 4735, 4762, 4768, 4788, 4796, 4807, 4816, 4831, 4840, 4856, 4858, 4868, 4881, 4892, 4897, 4922, 4927, 4950, 5008, 5009, 5018, 5030, 5035, 5053, 5055, 5085, 5088, 5110, 5119, 5122, 5136, 5140, 5149, 5183, 5215, 5241, 5261, 5302, 5303, 5315, 5318, 5336, 5356, 5371, 5396, 5397, 5443, 5451, 5454, 5460, 5487, 5489, 5494, 5495, 5504, 5546, 5564, 5596, 5599, 5604, 5609, 5610, 5617, 5623, 5651, 5654, 5677, 5688, 5716, 5743, 5754, 5769, 5779, 5783, 5807, 5821, 5822, 5823, 5829, 5830, 5839, 5842, 5875, 5876, 5885, 5896, 5955, 5971, 5973, 5993, 6008, 6010, 6024, 6036, 6048, 6089, 6093, 6098, 6118, 6131, 6149, 6159, 6181, 6225, 6240, 6246, 6247, 6252, 6285, 6310, 6322, 6324, 6367, 6372, 6378, 6383, 6389, 6395, 6401, 6431, 6440, 6460, 6461, 6477, 6479, 6481, 6484, 6490, 6526, 6542, 6546, 6556, 6558, 6571, 6583, 6589, 6598, 6604, 6625, 6632, 6635, 6636, 6650, 6731, 6733, 6744, 6755, 6767, 6775, 6782, 6797, 6811, 6839, 6857, 6861, 6884, 6894, 6911, 6974, 6982, 7009, 7017, 7018, 7026, 7030, 7051, 7053, 7063, 7066, 7081, 7085, 7102, 7127, 7147, 7179, 7194, 7199, 7221, 7225, 7234, 7261, 7284, 7287, 7306, 7346, 7369, 7386, 7394, 7433, 7454, 7463, 7469, 7471, 7472, 7527, 7529, 7538, 7540, 7542, 7544, 7570, 7610, 7620, 7633, 7634, 7688, 7727, 7751, 7758, 7798, 7819, 7848, 7881, 7889, 7893, 7907, 7934, 7970, 7978, 7996, 8001, 8006, 8008, 8011, 8021, 8026, 8031, 8038, 8046, 8057, 8087, 8089, 8091, 8097, 8098, 8100, 8106, 8115, 8116, 8138, 8152, 8158, 8162, 8172, 8186, 8213, 8224, 8249, 8256, 8265, 8286, 8293, 8315, 8327, 8332, 8354, 8356, 8390, 8396, 8436, 8442, 8460, 8477, 8509, 8527, 8534, 8559, 8573, 8602, 8628, 8632, 8634, 8673, 8675, 8679, 8699, 8707, 8715, 8768, 8779, 8790, 8818, 8826, 8842, 8847, 8947, 8955, 9056, 9065, 9067, 9068, 9069, 9078, 9102, 9107, 9159, 9205, 9208, 9218, 9222, 9239, 9244, 9262, 9265, 9281, 9303, 9304, 9307, 9327, 9361, 9374, 9384, 9400, 9403, 9431, 9445, 9447, 9463, 9532, 9548, 9584, 9611, 9637, 9643, 9654, 9677, 9697, 9698, 9718, 9758, 9782, 9789, 9815, 9948, 9959, 9969, 10015, 10026, 10031, 10052, 10071, 10084, 10111, 10116, 10133, 10151, 10160, 10195, 10238, 10276, 10309, 10310, 10325, 10336, 10421, 10429, 10437, 10438, 10465, 10470, 10472, 10480, 10495, 10503, 10506, 10511, 10542, 10593, 10606, 10607, 10688, 10691, 10693, 10698, 10729, 10735, 10742, 10797, 10832, 10840, 10856, 10880, 10893, 10901, 10935, 10976, 10980, 11005, 11048, 11050, 11087, 11108, 11122, 11133, 11147, 11190, 11201, 11220, 11233, 11252, 11309, 11339, 11349, 11350, 11361, 11386, 11397, 11405, 11416, 11471, 11502, 11507, 11510, 11513, 11568, 11586, 11614, 11639, 11643, 11646, 11689, 11746, 11748, 11771, 11781, 11843, 11863, 11904, 11920, 11952, 11972, 12020, 12050, 12055, 12082, 12098, 12100, 12113, 12122, 12145, 12151, 12158, 12171, 12201, 12205, 12209, 12212, 12217, 12220, 12246, 12282, 12293, 12327, 12329, 12343, 12378, 12433, 12458, 12462, 12476, 12484, 12488, 12542, 12556, 12557, 12561, 12573, 12609, 12625, 12656, 12678, 12738, 12743, 12767, 12775, 12781, 12792, 12797, 12805, 12822, 12825, 12834, 12854, 12897, 12907, 12941, 12942, 12949, 12950, 12972, 13005, 13037, 13059, 13081, 13098, 13129, 13149, 13166, 13171, 13177, 13180, 13187, 13200, 13217, 13220, 13221, 13228, 13244, 13266, 13335, 13351, 13355, 13364, 13385, 13424, 13428, 13434, 13483, 13486, 13535, 13541, 13552, 13554, 13580, 13581, 13588, 13664, 13673, 13709, 13718, 13755, 13822, 13840, 13876, 13903, 13969, 13972, 13992, 14013, 14073, 14089, 14107, 14115, 14117, 14135, 14142, 14167, 14168, 14202, 14225, 14228, 14259, 14272, 14318, 14354, 14385, 14391, 14448, 14463, 14483, 14491, 14492, 14615, 14618, 14621, 14643, 14664, 14697, 14700, 14703, 14708, 14721, 14731, 14766, 14771, 14777, 14780, 14814, 14870, 14894, 14917, 14964, 14989, 15015, 15019, 15033, 15036, 15037, 15091, 15092, 15093, 15104, 15119, 15120, 15133, 15148, 15173, 15194, 15226, 15298, 15330, 15344, 15357, 15414, 15437, 15453, 15459, 15474, 15526, 15546, 15573, 15605, 15623, 15661, 15682, 15694, 15721, 15724, 15753, 15763, 15766, 15789, 15805, 15807, 15839, 15841, 15850, 15864, 15868, 15884, 15893, 15900, 15922, 15956, 15978, 16055, 16057, 16151, 16216, 16224, 16231, 16232, 16233, 16246, 16281, 16291, 16292, 16305, 16316, 16335, 16387, 16402, 16406, 16410, 16423, 16435, 16442, 16468, 16478, 16500, 16538, 16586, 16625, 16718, 16738, 16759, 16769, 16793, 16806, 16808, 16813, 16828, 16841, 16847, 16852, 16939, 16943, 16960, 16987, 16989, 16991, 17010, 17023, 17114, 17116, 17134, 17140, 17155, 17169, 17237, 17288, 17295, 17296, 17317, 17321, 17323, 17327, 17330, 17348, 17353, 17354, 17381, 17393, 17396, 17405, 17494, 17498, 17513, 17546, 17549, 17563, 17602, 17633, 17642, 17670, 17681, 17690, 17691, 17699, 17726, 17768, 17770, 17783, 17796, 17802, 17834, 17838, 17869, 17870, 17880, 17891, 17915, 17926, 17967, 17985, 18003, 18027, 18069, 18109, 18185, 18196, 18227, 18242, 18246, 18251, 18274, 18295, 18315, 18350, 18391, 18393, 18406, 18407, 18409, 18456, 18465, 18471, 18486, 18499, 18502, 18514, 18522, 18532, 18548, 18556, 18584, 18594, 18598, 18606, 18634, 18652, 18667, 18691, 18815, 18854, 18860, 18874, 18888, 18891, 18897, 18962, 18965, 19010, 19050, 19054, 19066, 19071, 19153, 19158, 19165, 19166, 19237, 19294, 19305, 19314, 19315, 19369, 19384, 19404, 19411, 19433, 19439, 19453, 19563, 19575, 19581, 19591, 19641, 19660, 19661, 19693, 19704, 19732, 19734, 19783, 19785, 19796, 19803, 19813, 19816, 19837, 19846, 19875, 19887, 19905, 19962, 19967, 19985, 20003, 20025, 20033, 20043, 20070, 20134, 20211, 20233, 20234, 20237, 20261, 20330, 20375]\n"
     ]
    }
   ],
   "source": [
    "abstract_messages('final_dataset', 'unabstracted_cmg_dataset_with_removed_merge_commits_with_removed_not_single_colons_for_abstraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_methods_length(predicate, label):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    root = '../Tufano_data/'\n",
    "    with open(root + f'datasets/final_dataset/prev.txt', 'r') as prev_file, \\\n",
    "         open(root + f'datasets/final_dataset/updated.txt', 'r') as updated_file:\n",
    "        correct_idx = []\n",
    "        prev_lines = [l.strip() for l in prev_file]\n",
    "        updated_lines = [l.strip() for l in updated_file]\n",
    "        i = 0\n",
    "        for prev, updated in zip(prev_lines, updated_lines):\n",
    "            if predicate(prev.split(' '), updated.split(' ')):\n",
    "                correct_idx.append(i)\n",
    "            i += 1\n",
    "        print(label)\n",
    "        print(f'Result: {len(correct_idx)} / {len(prev_lines)} = {len(correct_idx) / len(prev_lines)}')\n",
    "        return correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All method pairs are <= 100\n",
      "Result: 6593 / 20410 = 0.3230279274865262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 8, 9, 11, 13, 14, 18, 20, 22, 23]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_methods_length(lambda p, u: len(p) <= 100 and len(u) <= 100, 'All method pairs are <= 100')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All method pairs are <= 150\n",
      "Result: 9519 / 20410 = 0.4663890249877511\n"
     ]
    }
   ],
   "source": [
    "out = analyze_methods_length(lambda p, u: len(p) <= 150 and len(u) <= 150, 'All method pairs are <= 150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All method pairs are <= 200\n",
      "Result: 11693 / 20410 = 0.5729054385105341\n"
     ]
    }
   ],
   "source": [
    "out = analyze_methods_length(lambda p, u: len(p) <= 200 and len(u) <= 200, 'All method pairs are <= 200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_methods_length(predicate, label):\n",
    "    import os\n",
    "    root = '../Tufano_data/'\n",
    "    idx = analyze_methods_length(predicate, label)\n",
    "    list_of_files = os.listdir(root + f'datasets/final_dataset/')\n",
    "    for filename in list_of_files:\n",
    "        with open(root + f'datasets/final_dataset/' + filename, 'r') as in_file, \\\n",
    "             open(root + f'datasets/final_dataset/filtered_' + filename, 'w') as out_file:\n",
    "            in_lines = [l.strip() for l in in_file]\n",
    "            filtered_lines = [in_lines[i] for i in idx]\n",
    "            out_file.write('\\n'.join(filtered_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All method pairs are <= 100\n",
      "Result: 6593 / 20410 = 0.3230279274865262\n"
     ]
    }
   ],
   "source": [
    "filter_by_methods_length(lambda p, u: len(p) <= 100 and len(u) <= 100, 'All method pairs are <= 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test():\n",
    "    import os\n",
    "    import random\n",
    "    root = '../Tufano_data/'\n",
    "    dataset_size = len([_ for _ in open(root + f'datasets/final_dataset/prev.txt', 'r')])\n",
    "    print(dataset_size)\n",
    "    idx = [i for i in range(dataset_size)]\n",
    "    random.shuffle(idx)\n",
    "    b1 = int(len(idx) * 0.8)\n",
    "    b2 = int(len(idx) * 0.9)\n",
    "    train_idx = idx[:b1]\n",
    "    val_idx = idx[b1:b2]\n",
    "    test_idx = idx[b2:]\n",
    "    print(f'train {len(train_idx)}, val {len(val_idx)}, test {len(test_idx)}')\n",
    "    print(f'test idx[:10]: {test_idx[:10]}')\n",
    "    list_of_files = os.listdir(root + f'datasets/final_dataset/')\n",
    "    for filename in list_of_files:\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "        with open(root + f'datasets/final_dataset/' + filename, 'r') as in_file:\n",
    "            in_lines = [l.strip() for l in in_file]\n",
    "            with open(root + f'datasets/final_dataset/train/' + filename, 'w') as out:\n",
    "                out.write('\\n'.join([in_lines[i] for i in train_idx]))\n",
    "            with open(root + f'datasets/final_dataset/val/' + filename, 'w') as out:\n",
    "                out.write('\\n'.join([in_lines[i] for i in val_idx]))\n",
    "            with open(root + f'datasets/final_dataset/test/' + filename, 'w') as out:\n",
    "                out.write('\\n'.join([in_lines[i] for i in test_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6593\n",
      "train 5274, val 659, test 660\n",
      "test idx[:10]: [3601, 4083, 2663, 5319, 5962, 361, 6212, 830, 5619, 1663]\n"
     ]
    }
   ],
   "source": [
    "split_train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
